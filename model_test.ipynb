{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevenLi8888/KRED/blob/test/model_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "3yeqNYik4viy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "668iCo4MqQFf",
        "outputId": "b3533f97-b505-46d8-d227-8e993708d8e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Secure GPU resource\n",
        "import torch\n",
        "placeholder = torch.Tensor([500, 500, 500]).cuda()"
      ],
      "metadata": {
        "id": "2POSy4FX5IXF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b test https://github.com/KevenLi8888/KRED.git"
      ],
      "metadata": {
        "id": "z9rmJKhM4rl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89882992-a50d-4205-80e6-0cee1a7a0dfe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KRED'...\n",
            "remote: Enumerating objects: 261, done.\u001b[K\n",
            "remote: Counting objects: 100% (261/261), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 261 (delta 148), reused 226 (delta 126), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (261/261), 44.15 MiB | 25.88 MiB/s, done.\n",
            "Resolving deltas: 100% (148/148), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir('/content/KRED')\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwA0iBrfrHyw",
        "outputId": "94dc78e2-4eb2-46d0-e6f4-f3ab1e216682"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/KRED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Developers/kg.zip ./data/kg\n",
        "!cp /content/drive/MyDrive/Developers/checkpoint.pt ./out"
      ],
      "metadata": {
        "id": "w5BC9EE7rRlU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "Mc-UjliO5Eav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ca1389-df71-4589-dd6b-1cf4d253759c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 15.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 54.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.11.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=16b2331313e59db2d56fbfc2c6650ba44a441748403b50db13e583a5dd850256\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.11.5 transformers-4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu | grep -E '^Thread|^Core|^Socket|^CPU\\('"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft0P2sUnpXjO",
        "outputId": "5e20d3e8-95ad-4253-ff94-97cffadc6879"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU(s):              2\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNoEa8rWpTdP",
        "outputId": "19b83807-0068-45cc-c7ce-d849594a0a61"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 25 08:11:36 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    27W /  70W |   1322MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hSHuJgdS4pG8"
      },
      "source": [
        "## Dataset Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51.7k/51.7k [00:01<00:00, 41.9kKB/s]\n",
            "100%|██████████| 30.2k/30.2k [00:01<00:00, 19.2kKB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from utils.util import *\n",
        "from train_test import *\n",
        "\n",
        "# Options: demo, small, large\n",
        "MIND_type = 'small'\n",
        "data_path = \"./data/\"\n",
        "\n",
        "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
        "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
        "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
        "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
        "knowledge_graph_file = os.path.join(data_path, 'kg/wikidata-graph', r'wikidata-graph.tsv')\n",
        "entity_embedding_file = os.path.join(data_path, 'kg/wikidata-graph', r'entity2vecd100.vec')\n",
        "relation_embedding_file = os.path.join(data_path, 'kg/wikidata-graph', r'relation2vecd100.vec')\n",
        "\n",
        "mind_url, mind_train_dataset, mind_dev_dataset, _ = get_mind_data_set(MIND_type)\n",
        "\n",
        "kg_url = \"https://kredkg.blob.core.windows.net/wikidatakg/\"\n",
        "\n",
        "if not os.path.exists(train_news_file):\n",
        "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
        "\n",
        "if not os.path.exists(valid_news_file):\n",
        "    download_deeprec_resources(mind_url, \\\n",
        "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
        "\n",
        "if not os.path.exists(knowledge_graph_file):\n",
        "    download_deeprec_resources(kg_url, \\\n",
        "                               os.path.join(data_path, 'kg'), \"kg.zip\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hqx7msLq4pHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54804275-3407-4748-904d-b0700bdf3398"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Config"
      ],
      "metadata": {
        "collapsed": false,
        "id": "MxiISGOc4pHG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('')\n",
        "sys.argv = [''] # added by me, solved problem in this cell\n",
        "\n",
        "import argparse\n",
        "from parse_config import ConfigParser\n",
        "\n",
        "parser = argparse.ArgumentParser(description='KRED')\n",
        "\n",
        "\n",
        "parser.add_argument('-c', '--config', default=\"./config.json\", type=str,\n",
        "                    help='config file path (default: None)')\n",
        "parser.add_argument('-r', '--resume', default=None, type=str,\n",
        "                    help='path to latest checkpoint (default: None)')\n",
        "parser.add_argument('-d', '--device', default=None, type=str,\n",
        "                    help='indices of GPUs to enable (default: all)')\n",
        "\n",
        "config = ConfigParser.from_args(parser)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kDsUxBuX4pHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Hyper-parameters"
      ],
      "metadata": {
        "collapsed": false,
        "id": "vV2JGZ2w4pHI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "batch_size = 256\n",
        "train_type = \"single_task\"\n",
        "task = \"user2item\" # task should be within: user2item, item2item, vert_classify, pop_predict\n",
        "\n",
        "config['trainer']['epochs'] = epochs\n",
        "config['data_loader']['batch_size'] = batch_size\n",
        "config['trainer']['training_type'] = train_type\n",
        "config['trainer']['task'] = task"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CDuGmLMA4pHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Test Data and Model"
      ],
      "metadata": {
        "id": "pSR9bojtuO7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = get_user2item_test_data(config)\n",
        "model = torch.load('./out/checkpoint.pt')\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtx3RhtyuTNv",
        "outputId": "10aa1a16-b3ae-44ff-d48e-a09fb20fd626"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KREDModel(\n",
              "  (news_embedding): News_embedding(\n",
              "    (kgat): KGAT(\n",
              "      (attention_layer1): Linear(in_features=300, out_features=128, bias=True)\n",
              "      (attention_layer2): Linear(in_features=128, out_features=1, bias=True)\n",
              "      (softmax): Softmax(dim=-1)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (convolve_layer): Linear(in_features=200, out_features=100, bias=True)\n",
              "    )\n",
              "    (final_embedding1): Linear(in_features=868, out_features=128, bias=True)\n",
              "    (final_embedding2): Linear(in_features=128, out_features=100, bias=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "    (tanh): Tanh()\n",
              "    (title_embeddings): Embedding(1000, 100)\n",
              "    (type_embeddings): Embedding(100, 100)\n",
              "    (entity_num_embeddings): Embedding(100, 100)\n",
              "    (attention_embedding_layer1): Linear(in_features=868, out_features=128, bias=True)\n",
              "    (attention_embedding_layer2): Linear(in_features=128, out_features=1, bias=True)\n",
              "    (softmax): Softmax(dim=-2)\n",
              "  )\n",
              "  (user_modeling): User_modeling(\n",
              "    (news_embedding): News_embedding(\n",
              "      (kgat): KGAT(\n",
              "        (attention_layer1): Linear(in_features=300, out_features=128, bias=True)\n",
              "        (attention_layer2): Linear(in_features=128, out_features=1, bias=True)\n",
              "        (softmax): Softmax(dim=-1)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (convolve_layer): Linear(in_features=200, out_features=100, bias=True)\n",
              "      )\n",
              "      (final_embedding1): Linear(in_features=868, out_features=128, bias=True)\n",
              "      (final_embedding2): Linear(in_features=128, out_features=100, bias=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "      (tanh): Tanh()\n",
              "      (title_embeddings): Embedding(1000, 100)\n",
              "      (type_embeddings): Embedding(100, 100)\n",
              "      (entity_num_embeddings): Embedding(100, 100)\n",
              "      (attention_embedding_layer1): Linear(in_features=868, out_features=128, bias=True)\n",
              "      (attention_embedding_layer2): Linear(in_features=128, out_features=1, bias=True)\n",
              "      (softmax): Softmax(dim=-2)\n",
              "    )\n",
              "    (user_attention_layer1): Linear(in_features=100, out_features=128, bias=True)\n",
              "    (user_attention_layer2): Linear(in_features=128, out_features=1, bias=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (softmax): Softmax(dim=0)\n",
              "  )\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax(dim=-1)\n",
              "  (mlp_layer1): Linear(in_features=200, out_features=128, bias=True)\n",
              "  (mlp_layer2): Linear(in_features=128, out_features=1, bias=True)\n",
              "  (cos): CosineSimilarity()\n",
              "  (vert_mlp_layer1): Linear(in_features=100, out_features=128, bias=True)\n",
              "  (vert_mlp_layer2): Linear(in_features=128, out_features=15, bias=True)\n",
              "  (local_mlp_layer1): Linear(in_features=100, out_features=128, bias=True)\n",
              "  (local_mlp_layer2): Linear(in_features=128, out_features=1, bias=True)\n",
              "  (pop_mlp_layer1): Linear(in_features=100, out_features=128, bias=True)\n",
              "  (pop_mlp_layer2): Linear(in_features=128, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from utils.metrics import *\n",
        "\n",
        "y_pred = []\n",
        "start_list = list(range(0, 256, config['data_loader']['batch_size'])) # range(start, stop[, step])\n",
        "for start in tqdm(start_list):\n",
        "    if start + config['data_loader']['batch_size'] <= len(test_data['label']):\n",
        "        end = start + config['data_loader']['batch_size']\n",
        "    else:\n",
        "        end = len(test_data['label'])\n",
        "    # had to change 'user_id' to 'item1' and 'news_id' to 'item2' according to key declarations in utils.util load_data_mind function\n",
        "    # out = model(test_data['item1'][start:end], test_data['item2'][start:end], config['data_loader']['batch_size'])[0].cpu().data.numpy()\n",
        "    out = model(test_data['item1'][start:end], test_data['item2'][start:end], config['data_loader']['batch_size'])[0].cpu().data.numpy()\n",
        "    y_pred.extend(out)\n",
        "truth = test_data['label'][0:256]\n",
        "score = evaluate(y_pred, truth, test_data, config['trainer']['task'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHdw33ul9tXT",
        "outputId": "42c1f277-4fbb-4f81-844a-cf7424a7d74a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score:0.7197786998616874\n",
            "ndcg score:0.5517282238681521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "model_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}